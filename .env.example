OPENAI_API_KEY=

# Optional tuning
OPENAI_MODEL=gpt-5.2
OPENAI_TEMPERATURE=0.1

# Optional: path for the CSV output file (default: papers_pipeline.csv)
CSV_OUTPUT_PATH=papers_pipeline.csv

# Post-run report files (generated automatically after every non-dry-run)
DEBATED_REPORT_PATH=papers_debated.csv
TOP_PICKS_REPORT_PATH=papers_top_picks.csv
TOP_PICKS_N=15

# Optional: how far back to look for HF Daily Papers (default: 180 days ≈ 6 months).
# Increase to backfill older papers; set to 1 for strict daily-only mode.
HF_MAX_AGE_DAYS=180

# Optional: how many past days to fetch from the HF API (default: 7).
# Each day returns ~50 papers; they are deduplicated across days before processing.
# Set to 90 for ~3 months of coverage (~2,000-3,000 unique papers before dedup).
HF_FETCH_DAYS=90

# Stage 3 — Claude two-agent debate (optional)
# Leave ANTHROPIC_API_KEY blank to skip the debate stage gracefully.
ANTHROPIC_API_KEY=
CLAUDE_MODEL=claude-opus-4-6

# Debate gate: paper must clear BOTH conditions to trigger Stage 3.
#   1. overall_score >= AGENTIC_MIN_OVERALL_SCORE
#   2. startup_potential >= 4 OR market_pull >= 4  (at least one commercial signal)
# Raise AGENTIC_MIN_OVERALL_SCORE to be more selective; lower to debate more papers.
AGENTIC_MIN_OVERALL_SCORE=4

# --mode wide_scout — broad sweep with capped LLM spend
# Fetches MAX_FETCH_DAYS_WIDE days (default: 180 ≈ 6 months) of HF papers.
# Scores up to MAX_LLM_PAPERS_WIDE papers with OpenAI (Stage 2).
# Runs Stage 3-4 only on the top MAX_DEEP_PAPERS_WIDE papers; set to 0 to skip entirely.
# Results go to WIDE_SCOUT_CSV_PATH (separate from papers_pipeline.csv).
MAX_FETCH_DAYS_WIDE=180
MAX_LLM_PAPERS_WIDE=500
MAX_DEEP_PAPERS_WIDE=0
WIDE_SCOUT_CSV_PATH=papers_wide_scout.csv
